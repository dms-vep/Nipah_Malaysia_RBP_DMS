{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "031d7b1a-ee98-45c8-8224-fc355e91e1c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# This notebook analyzes features of henipavirus and nipah sequence conservation and compares to DMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a89531-6abf-4dac-a6c8-477383142c4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#this cell is tagged as parameters for `papermill` parameterization\n",
    "altair_config = None\n",
    "nipah_config = None\n",
    "\n",
    "e2_binding = None\n",
    "e2_entry = None\n",
    "\n",
    "e3_binding = None\n",
    "e3_entry = None\n",
    "\n",
    "nipah_alignment = None\n",
    "\n",
    "entropy_output = None\n",
    "entry_scores_niv_poly = None\n",
    "binding_scores_niv_poly = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4b7bc-1ab5-4698-a21b-6b9bc6194e78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "\n",
    "import subprocess\n",
    "import tempfile\n",
    "import yaml\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Align import PairwiseAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a5407-b027-4297-9c0f-5cb6ad0b963c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# allow more rows for Altair\n",
    "_ = alt.data_transformers.disable_max_rows()\n",
    "\n",
    "if os.getcwd() == '/fh/fast/bloom_j/computational_notebooks/blarsen/2023/Nipah_Malaysia_RBP_DMS/':\n",
    "    pass\n",
    "    print(\"Already in correct directory\")\n",
    "else:\n",
    "    os.chdir(\"/fh/fast/bloom_j/computational_notebooks/blarsen/2023/Nipah_Malaysia_RBP_DMS/\")\n",
    "    print(\"Setup in correct directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede4772-4260-41a9-a3d4-333f7eeb9de2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if nipah_alignment is None:\n",
    "    altair_config = 'data/custom_analyses_data/theme.py'\n",
    "    nipah_config = 'nipah_config.yaml'\n",
    "    e2_binding = 'results/receptor_affinity/averages/EFNB2_monomeric_mut_effect.csv'\n",
    "    e2_entry = 'results/func_effects/averages/CHO_EFNB2_low_func_effects.csv'\n",
    "    e3_binding = 'results/receptor_affinity/averages/EFNB3_dimeric_mut_effect.csv'\n",
    "    e3_entry = 'results/func_effects/averages/CHO_EFNB3_low_func_effects.csv'\n",
    "    nipah_alignment = 'data/custom_analyses_data/alignments/Nipah_RBP_AA_align.fasta'\n",
    "    entropy_output = 'results/entropy/entropy.csv'\n",
    "    entry_scores_niv_poly = 'results/images/niv_polymorphic_entry.html'\n",
    "    binding_scores_niv_poly = 'results/images/niv_polymorphic_binding.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c6823-dafc-4856-aebe-b6a403d0b7dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if altair_config:\n",
    "    with open(altair_config, 'r') as file:\n",
    "        exec(file.read())\n",
    "\n",
    "with open(nipah_config) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62053a-68da-434a-aa64-0d085b4c4641",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Pull in cell entry and binding scores and pre-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f672292-bd83-41c0-b8fa-5f689a0dd9e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make E2 monomeric\n",
    "e2 = pd.read_csv(e2_binding)\n",
    "e2_func = pd.read_csv(e2_entry)\n",
    "df_E2 = pd.merge(\n",
    "    e2_func,\n",
    "    e2, \n",
    "    on=['site','mutant','wildtype'],\n",
    "    suffixes=['_cell_entry','_affinity'],\n",
    "    validate='one_to_one',\n",
    "    how='outer'\n",
    ")\n",
    "df_E2 = df_E2.rename(columns={'Ephrin binding_mean':'binding_mean','Ephrin binding_std':'binding_std','Ephrin binding_median':'binding_median'})\n",
    "\n",
    "# Now do E3\n",
    "e3 = pd.read_csv(e3_binding)\n",
    "e3_func = pd.read_csv(e3_entry)\n",
    "df_E3 = pd.merge(\n",
    "    e3_func,\n",
    "    e3,\n",
    "    on=['site','mutant','wildtype'],\n",
    "    suffixes=['_cell_entry','_affinity'],\n",
    "    validate='one_to_one',\n",
    "    how='outer'\n",
    ")\n",
    "df_E3 = df_E3.rename(columns={'Ephrin binding_mean':'binding_mean','Ephrin binding_std':'binding_std','Ephrin binding_median':'binding_median'})\n",
    "\n",
    "# don't filter binding mutants, just cell entry\n",
    "def filter_df(df):\n",
    "    df_filter = df[\n",
    "        #(df['effect'] >= -1.5) &\n",
    "        #(df['frac_models'] >= 0.5) &\n",
    "        (df['mutant'] != '*') &\n",
    "        (df['mutant'] != '-') &\n",
    "        (df['site'] != 603) &\n",
    "        (df['times_seen_cell_entry'] >= config['func_times_seen_cutoff']) &\n",
    "        #(df['times_seen_affinity'] >= config[') &\n",
    "        #(df['binding_std'] <= 1.5) &\n",
    "        (df['effect_std'] <= config['func_std_cutoff']) \n",
    "        #(df['frac_models'] >= 0.5)\n",
    "    ]\n",
    "    #df_filter = df_filter.sort_values(by='binding_mean',ascending=False)\n",
    "    return df_filter\n",
    "\n",
    "\n",
    "df_E2_filter = filter_df(df_E2)\n",
    "df_E3_filter = filter_df(df_E3)\n",
    "\n",
    "df_affinity_filter_merge = pd.merge(\n",
    "    df_E2_filter,\n",
    "    df_E3_filter,\n",
    "    on=['site','wildtype','mutant'],\n",
    "    suffixes=['_E2','_E3'],\n",
    "    how='outer'\n",
    ")\n",
    "df_affinity_filter_merge['func_effect_diff'] = (df_affinity_filter_merge['effect_E2'] - df_affinity_filter_merge['effect_E3']).abs()\n",
    "df_affinity_filter_merge['binding_effect_diff'] = (df_affinity_filter_merge['binding_mean_E2'] - df_affinity_filter_merge['binding_mean_E3']).abs()\n",
    "\n",
    "df_assign = df_affinity_filter_merge[['site','wildtype','mutant','effect_E2','binding_median_E2','binding_std_E2','effect_E3','binding_median_E3','binding_std_E3']]\n",
    "display(df_assign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489f81a-1876-4bbc-a6b2-be6519b2ec55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Pull represantative henipavirus RBP amino acid sequences from genbank, align, calculate entropy, and convert to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c28cfe-9ce1-4d7a-8ddf-159d240863f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shannon_entropy(column):\n",
    "    \"\"\"Compute the Shannon entropy of a column in the alignment.\"\"\"\n",
    "    counts = {}\n",
    "    for aa in column:\n",
    "        if aa in counts:\n",
    "            counts[aa] += 1\n",
    "        else:\n",
    "            counts[aa] = 1\n",
    "\n",
    "    entropy = 0.0\n",
    "    for key in counts:\n",
    "        freq = counts[key] / len(column)\n",
    "        entropy += freq * math.log2(freq)\n",
    "    return -entropy\n",
    "\n",
    "def fetch_and_align(accession_numbers, email, output_folder=\".\"):\n",
    "    \"\"\"\n",
    "    Fetch sequences from GenBank based on accession numbers, align them,\n",
    "    and return the alignment as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - accession_numbers: List of accession numbers.\n",
    "    - email: Email address to be used with NCBI's Entrez.\n",
    "    - output_folder: The directory where output files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame representation of the alignment.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists, if not, create it.\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Fetch sequences from GenBank\n",
    "    Entrez.email = email\n",
    "    sequences = []\n",
    "    for acc in accession_numbers:\n",
    "        handle = Entrez.efetch(db=\"protein\", id=acc, rettype=\"fasta\", retmode=\"text\")\n",
    "        seq_record = SeqIO.read(handle, \"fasta\")\n",
    "        sequences.append(seq_record)\n",
    "        handle.close()\n",
    "\n",
    "    # Define file paths\n",
    "    temp_sequences_path = os.path.join(output_folder, \"temp_sequences.fasta\")\n",
    "    aligned_path = os.path.join(output_folder, \"aligned.fasta\")\n",
    "\n",
    "    # Write sequences to a temporary fasta file\n",
    "    SeqIO.write(sequences, temp_sequences_path, \"fasta\")\n",
    "\n",
    "    # Align using MUSCLE (you might need to adjust the path to the MUSCLE executable)\n",
    "    muscle_exe = \"/fh/fast/bloom_j/software/miniconda3/envs/BloomLab/bin/muscle\"\n",
    "    muscle_result = subprocess.check_output([muscle_exe, \"-align\", temp_sequences_path, \"-output\", aligned_path])\n",
    "\n",
    "    # Read the aligned sequences\n",
    "    alignment = AlignIO.read(aligned_path, \"fasta\")\n",
    "\n",
    "    # Convert alignment to DataFrame\n",
    "    alignment_dict = {record.id: list(record.seq) for record in alignment}\n",
    "    df_alignment = pd.DataFrame(alignment_dict)\n",
    "    df_alignment = df_alignment.rename(columns={'YP_009094086.1':'cedar','AFH96011.1':'ghana','NP_112027.1':'nipah','NP_047112.2':'hendra','UCY33670.1':'hendra_G2','QDJ04463.1':'nipah_cambodia','QKV44014.1':'nipah_india','YP_009094095.1':'Mojiang','UUV47206.1':'Langya','AJP33320.1':'cedar_2'})\n",
    "    \n",
    "    # Calculate and add Shannon entropy for each site to the dataframe\n",
    "    df_alignment['henipavirus_entropy'] = [shannon_entropy(df_alignment.iloc[i]) for i in range(df_alignment.shape[0])]\n",
    "    \n",
    "    return df_alignment\n",
    "\n",
    "# Pull these genbank sequences\n",
    "cedar = 'YP_009094086.1'\n",
    "cedar2 = 'AJP33320.1'\n",
    "ghana = 'AFH96011.1'\n",
    "nipah = 'NP_112027.1',\n",
    "nipah_cambodia = 'QDJ04463.1'\n",
    "nipah_india = 'QKV44014.1'\n",
    "hendra = 'NP_047112.2'\n",
    "hendra_G2 = 'UCY33670.1'\n",
    "\n",
    "seqs = [cedar, cedar2, ghana, nipah, nipah_cambodia, nipah_india, hendra, hendra_G2]\n",
    "output_folder = \"results/alignments/\"\n",
    "df = fetch_and_align(seqs, \"blarsen@fredhutch.org\", output_folder)\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838118ca-a8bc-4005-8a19-c3f9101f2db4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Make site numbering relative to Nipah reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d8c04-f6e8-4723-bd25-f6023efc7317",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a boolean mask for the 'nipah' column\n",
    "mask = df['nipah'] != '-'\n",
    "# Use cumsum to count the occurrences and assign it to a new column 'site'\n",
    "df['site'] = mask.cumsum()\n",
    "# Reset the count to 0 for rows where 'nipah' is '-'\n",
    "df.loc[~mask, 'site'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f501f-db40-433e-8854-304f0a616131",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save file for other notebooks use\n",
    "df.to_csv(entropy_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba869a-fa4b-4766-b204-7ca64106b4cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculate Which Sites are 100% conserved across represantative henipavirus sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5485411-8a7a-456f-bb9a-124fda77c767",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevant_columns = df.drop(columns=['henipavirus_entropy', 'site'])\n",
    "df['conserved'] = relevant_columns.apply(lambda row: len(set(row)) == 1, axis=1)\n",
    "conserved_sites = df[df['conserved']]['site'].sort_values().tolist()\n",
    "print(f\" These sites are completely conserved among represantative Henipaviruses: {conserved_sites}\")\n",
    "print(f\" The number of sites conserved across all Henipaviruses are: {len(conserved_sites)}\")\n",
    "df_merged = pd.merge(df_assign, df, on='site', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527e9c1-dc20-449b-b810-4a3322af0322",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot median cell entry at sites conserved in henipaviruses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa3e03-2065-4966-8af9-a5be3d17a1c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_conserved_sites(df):\n",
    "    df_subset = df.loc[df['site'].isin(conserved_sites)]\n",
    "    df_melted = df_subset.melt(id_vars=['site','wildtype','mutant'], value_vars=['effect_E2', 'effect_E3'], var_name='type', value_name='effect')\n",
    "    df_melted['type'] = df_melted['type'].replace({'effect_E2': 'EFNB2', 'effect_E3': 'EFNB3'})\n",
    "    \n",
    "    df_melted = df_melted.groupby(['site','type'])['effect'].median().reset_index()\n",
    "    chart = alt.Chart(df_melted).mark_point(size = 100, filled=True,opacity=1).encode(\n",
    "        x = alt.X('site:N',title='Site', axis=alt.Axis(grid=True,labelAngle=-45)),\n",
    "        y = alt.Y('effect',title='Mean Cell Entry by RBP Mutants'),\n",
    "        #tooltip=['site','wildtype','mutant','type'],\n",
    "        color = alt.Color('type', legend=alt.Legend(title='Cell Type')),\n",
    "    ).properties(\n",
    "        width=alt.Step(20),\n",
    "        height=alt.Step(20)\n",
    "    )\n",
    "\n",
    "    return chart.display()\n",
    "\n",
    "plot_conserved_sites(df_assign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f70592-cc77-4530-9af9-f8502dc925c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Calculate entropy from Nipah sequence alignment of RBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b17ce5-be7f-486a-866d-10c7e0cefff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_path = nipah_alignment\n",
    "alignment = AlignIO.read(alignment_path, \"fasta\")\n",
    "\n",
    "# Convert alignment to DataFrame\n",
    "alignment_dict = {record.id: list(record.seq) for record in alignment}\n",
    "df_alignment = pd.DataFrame(alignment_dict)\n",
    "display(df_alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb99ec4-3b3b-4dab-8986-16aa115514ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shannon_entropy_and_mutant_aa(column, wildtype_aa):\n",
    "    \"\"\"\n",
    "    Compute the Shannon entropy of a column in the alignment and return the top amino acid excluding the wildtype.\n",
    "    \n",
    "    Parameters:\n",
    "    - column: A column from a sequence alignment, representing one site across multiple sequences.\n",
    "    - wildtype_aa: The wildtype (original) amino acid at this position in a reference sequence.\n",
    "    \n",
    "    Returns:\n",
    "    - The Shannon entropy of the column (a measure of diversity).\n",
    "    - The amino acid variant that appears most frequently, excluding the wildtype.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to count occurrences of each amino acid\n",
    "    counts = {}\n",
    "    # Iterate through each amino acid in the column\n",
    "    for aa in column:\n",
    "        # Ignore gap ('-') and unknown ('X') characters\n",
    "        if aa not in [\"-\", \"X\"]:\n",
    "            # If the amino acid is already in the dictionary, increment its count\n",
    "            if aa in counts:\n",
    "                counts[aa] += 1\n",
    "            # Otherwise, add it to the dictionary with a count of 1\n",
    "            else:\n",
    "                counts[aa] = 1\n",
    "    \n",
    "    # If counts is empty after filtering, return 0.0 entropy and None for the mutant amino acid\n",
    "    if not counts:\n",
    "        return 0.0, None\n",
    "      \n",
    "    # Calculate Shannon entropy\n",
    "    entropy = 0.0\n",
    "    for key in counts:\n",
    "        freq = counts[key] / sum(counts.values())  # Calculate frequency of each amino acid\n",
    "        entropy += freq * math.log2(freq)  # Add the frequency times the log base 2 of the frequency to the entropy\n",
    "\n",
    "    # Remove the wildtype amino acid from counts if it's present\n",
    "    counts.pop(wildtype_aa, None)\n",
    "    # Sort the amino acids by frequency to find the mutant\n",
    "    sorted_aas = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    mutant_aa = sorted_aas[0][0] if sorted_aas and sorted_aas[0][1] > 2 else None\n",
    "    # Correctly select the top amino acid if any exist\n",
    "    #mutant_aa = sorted_aas[0][0] if sorted_aas else None\n",
    "    \n",
    "    # Return the negative entropy (since entropy is traditionally a measure of disorder, negative entropy can be seen as order) and the mutant amino acid\n",
    "    return -entropy, mutant_aa\n",
    "\n",
    "# Path to the alignment file (presumed defined elsewhere in your code)\n",
    "alignment_path = nipah_alignment\n",
    "# Read the alignment file using BioPython's AlignIO\n",
    "alignment = AlignIO.read(alignment_path, \"fasta\")\n",
    "\n",
    "# Convert the alignment to a pandas DataFrame for easier manipulation\n",
    "alignment_dict = {record.id: list(record.seq) for record in alignment}\n",
    "df_alignment = pd.DataFrame(alignment_dict)\n",
    "\n",
    "# Extract the wildtype sequence from the DataFrame\n",
    "wildtype_series = df_alignment['NC_002728.1_Nipah_virus_complete_genome']\n",
    "\n",
    "# Compute entropy and mutant amino acid for each site in the alignment\n",
    "values = [shannon_entropy_and_mutant_aa(df_alignment.iloc[i], wildtype_series[i]) for i in range(df_alignment.shape[0])]\n",
    "# Unpack the computed values into two lists: entropies and mutants\n",
    "entropies, mutants = zip(*values)\n",
    "\n",
    "# Create a final DataFrame to hold the computed values along with site numbers\n",
    "df_final = pd.DataFrame({\n",
    "    'site': range(1, len(mutants) + 1),\n",
    "    'entropy': entropies,\n",
    "    'wildtype': wildtype_series,\n",
    "    'mutant': mutants\n",
    "})\n",
    "\n",
    "# Filter to get rid of extra site at end\n",
    "df_final = df_final[df_final['site'] < 603]\n",
    "#display(df_final[df_final)\n",
    "#df_mutations are all sites that have polymorphisms in Nipah sequences\n",
    "df_mutations = pd.merge(df_final,df_assign,on=['site','wildtype','mutant'],how='inner')\n",
    "\n",
    "#df_total is data frame with all information\n",
    "df_total = pd.merge(df_merged,df_final,on=['site'])\n",
    "df_total = df_total.rename(columns={'wildtype_y':'nipahM_con','mutant_y':'nipahM_minor','wildtype_x':'wildtype','mutant_x':'mutant'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc3bdf-c582-4437-ab93-5c0619207987",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3862b-b4d3-4137-9dc0-ad2a48ed7aed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Find all sites that were mutagenized with a polymophism in NiV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b9135-0f05-4fdf-8627-aae93612dfa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites_with_mutants = df_final.loc[df_final['mutant'].notnull(), 'site'].tolist()\n",
    "polymorphisms = list(sites_with_mutants)\n",
    "print(polymorphisms)\n",
    "data_series = pd.Series(polymorphisms)  \n",
    "filtered_series = data_series[data_series > 70]\n",
    "polymorphisms = list(filtered_series)\n",
    "polymorphism_length = len(polymorphisms)\n",
    "print(polymorphism_length)\n",
    "print(f'These are a list of polymorphic sites in NiV RBP sequences: {polymorphisms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219c00a-98e8-4271-82a2-385d2e3e4d8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the 5th and 95th percentiles\n",
    "lower_limit_E3_binding = df_total['binding_median_E3'].dropna().quantile(0.05)\n",
    "median_E3_binding = df_total['binding_median_E3'].dropna().quantile(0.50)\n",
    "upper_limit_E3_binding = df_total['binding_median_E3'].dropna().quantile(0.95)\n",
    "\n",
    "print(f\"Lower limit (5th percentile): {lower_limit_E3_binding:.2f}\")\n",
    "print(f\"Upper limit (95th percentile): {upper_limit_E3_binding:.2f}\")\n",
    "\n",
    "# Find the 5th and 95th percentiles\n",
    "lower_limit_E2_binding = df_total['binding_median_E2'].dropna().quantile(0.05)\n",
    "median_E2_binding = df_total['binding_median_E2'].dropna().quantile(0.50)\n",
    "upper_limit_E2_binding = df_total['binding_median_E2'].dropna().quantile(0.95)\n",
    "\n",
    "print(f\"Lower limit (5th percentile): {lower_limit_E2_binding:.2f}\")\n",
    "print(f\"Upper limit (95th percentile): {upper_limit_E2_binding:.2f}\")\n",
    "\n",
    "# Find the 5th and 95th percentiles\n",
    "lower_limit_E2_entry = df_total['effect_E2'].dropna().quantile(0.05)\n",
    "median_E2_entry = df_total['effect_E2'].dropna().quantile(0.50)\n",
    "upper_limit_E2_entry = df_total['effect_E2'].dropna().quantile(0.95)\n",
    "\n",
    "print(f\"Lower limit (5th percentile): {lower_limit_E2_entry:.2f}\")\n",
    "print(f\"Upper limit (95th percentile): {upper_limit_E2_entry:.2f}\")\n",
    "\n",
    "# Find the 5th and 95th percentiles\n",
    "lower_limit_E3_entry = df_total['effect_E3'].dropna().quantile(0.05)\n",
    "median_E3_entry = df_total['effect_E3'].dropna().quantile(0.50)\n",
    "upper_limit_E3_entry = df_total['effect_E3'].dropna().quantile(0.95)\n",
    "\n",
    "print(f\"Lower limit (5th percentile): {lower_limit_E3_entry:.2f}\")\n",
    "print(f\"Upper limit (95th percentile): {upper_limit_E3_entry:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0d188-b03b-469d-b71a-13de9449b0aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If I draw random samples of size x, what is probability I get an observation in there as high as observed?\n",
    "def random_draws(df,column,threshold):\n",
    "    num_trials = 1000  \n",
    "    count = 0  \n",
    "    x = polymorphism_length\n",
    "    for _ in range(num_trials):\n",
    "        sample = df[column].dropna().sample(n=x, replace=True)\n",
    "        # Check if any value in the sample is above 1\n",
    "        if any(sample > threshold):\n",
    "            count += 1\n",
    "    \n",
    "        # Calculate the fraction of times at least one observation above 1 was found\n",
    "        fraction = count / num_trials\n",
    "        fraction\n",
    "    print(f'The fraction of times a random draw of {column} included a value greater than {threshold:.2f} was {fraction:.2f}')\n",
    "df_total_polymorphic = df_total[df_total['site'].isin(polymorphisms)]\n",
    "\n",
    "columns = ['effect_E2','effect_E3','binding_median_E2','binding_median_E3']\n",
    "for column_name in columns:\n",
    "    if column_name == 'effect_E2':\n",
    "        random_draws(df_total_polymorphic,column_name,df_mutations['effect_E2'].max())\n",
    "    if column_name == 'effect_E3':\n",
    "        random_draws(df_total_polymorphic,column_name,df_mutations['effect_E3'].max())\n",
    "    if column_name == 'binding_mean_E2':\n",
    "        random_draws(df_total_polymorphic,column_name,df_mutations['binding_median_E2'].max())\n",
    "    if column_name == 'binding_mean_E3':\n",
    "        random_draws(df_total_polymorphic,column_name,df_mutations['binding_median_E3'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e4f13-1095-4fe4-95bf-1cad4c039274",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot Nipah Polymorphisms Cell Entry Scores by Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd59ac-4042-470f-aa64-286d3b8f0cfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats(df,column):\n",
    "    df = df[column].dropna()\n",
    "    df_clean = df_mutations[column].dropna()\n",
    "    mean = df.mean()\n",
    "    median = df.median()\n",
    "    std = df.std()\n",
    "    print(f'The mean for {column} is: {mean:.2f}')\n",
    "    print(f'The median for {column} is: {median:.2f}')\n",
    "    print(f'The std for {column} is: {std:.2f}')\n",
    "    t_statistic, p_value = stats.ttest_1samp(df_clean, mean)\n",
    "    print(f'The p_value for {column} is: {p_value:.3f}')\n",
    "    print('')\n",
    "    return mean,std\n",
    "\n",
    "columns = ['effect_E2','effect_E3','binding_median_E2','binding_median_E3']\n",
    "for column_name in columns:\n",
    "    if column_name == 'effect_E2':\n",
    "        effect_E2_mean,effect_E2_std = get_stats(df_total,column_name)\n",
    "    if column_name == 'effect_E3':\n",
    "        effect_E3_mean,effect_E3_std = get_stats(df_total,column_name)\n",
    "    if column_name == 'binding_median_E2':\n",
    "        binding_E2_mean,binding_E2_std = get_stats(df_total,column_name)\n",
    "    if column_name == 'binding_median_E3':\n",
    "        binding_E3_mean,binding_E3_std = get_stats(df_total,column_name)\n",
    "    #get_stats(df_total,column_name)\n",
    "\n",
    "effect_E2_min = effect_E2_mean - 2 * effect_E2_std\n",
    "effect_E2_max = effect_E2_mean + 2 * effect_E2_std\n",
    "print(f'The max and min of effect_E2 are: {effect_E2_min:.2f} and {effect_E2_max:.2f}')\n",
    "\n",
    "effect_E3_min = effect_E3_mean - 2 * effect_E3_std\n",
    "effect_E3_max = effect_E3_mean + 2 * effect_E3_std\n",
    "print(f'The max and min of effect_E2 are: {effect_E3_min:.2f} and {effect_E3_max:.2f}')\n",
    "\n",
    "binding_E2_min = binding_E2_mean - 2 * binding_E2_std\n",
    "binding_E2_max = binding_E2_mean + 2 * binding_E2_std\n",
    "print(f'The max and min of effect_E2 are: {binding_E2_min:.2f} and {binding_E2_max:.2f}')\n",
    "\n",
    "binding_E3_min = binding_E3_mean - 2 * binding_E3_std\n",
    "binding_E3_max = binding_E3_mean + 2 * binding_E3_std\n",
    "print(f'The max and min of effect_E2 are: {binding_E3_min:.2f} and {binding_E3_max:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0385821-85d9-4ba4-b7a6-105dacb8d02f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot cell entry of all naturally occuring nipah mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c82765-d7a8-40f9-9b71-c69904224dbb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_functional_effect_polymorphism(df):\n",
    "    df_mutations = df.rename(columns={'effect_E2':'EFNB2','effect_E3':'EFNB3'})\n",
    "    df_melted = df_mutations.melt(id_vars=['site','wildtype','mutant'], value_vars=['EFNB2','EFNB3'], \n",
    "                                  var_name='effect', value_name='value')\n",
    "    charts = []\n",
    "    \n",
    "    for effect in ['EFNB2','EFNB3']: \n",
    "        base = alt.Chart(df_melted,title=f'{effect}').encode(\n",
    "            x=alt.X('site:N', title='Site', axis=alt.Axis(labelAngle=-90),\n",
    "                    scale=alt.Scale(domain=list(polymorphisms))),\n",
    "            y=alt.Y('value:Q', title='Cell Entry'),\n",
    "            tooltip=['effect', 'value', 'site', 'mutant', 'wildtype']\n",
    "        ).transform_filter(\n",
    "            alt.datum.effect == effect\n",
    "        ).properties(\n",
    "            width=500,\n",
    "            height=100#alt.Step(5)\n",
    "        )\n",
    "\n",
    "        chart_effect = base.mark_circle(size=100,opacity=1,color='black').encode(\n",
    "            #color=alt.Color('effect:N', scale=alt.Scale(domain=['EFNB2', 'EFNB3'], range=['#1f4e79', '#ff7f0e']),legend=None)\n",
    "        )\n",
    "        \n",
    "        if effect == 'EFNB2':\n",
    "            rule95 = alt.Chart(pd.DataFrame({'y': [upper_limit_E2_entry]})).mark_rule(color='black', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule50 = alt.Chart(pd.DataFrame({'y': [median_E2_entry]})).mark_rule(color='#black', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule5 = alt.Chart(pd.DataFrame({'y': [lower_limit_E2_entry]})).mark_rule(color='#black', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "        else:  # effect is EFNB3\n",
    "            rule95 = alt.Chart(pd.DataFrame({'y': [upper_limit_E3_entry]})).mark_rule(color='#black', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule50 = alt.Chart(pd.DataFrame({'y': [median_E3_entry]})).mark_rule(color='#black', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule5 = alt.Chart(pd.DataFrame({'y': [lower_limit_E3_entry]})).mark_rule(color='#black', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "\n",
    "        chart = alt.layer(chart_effect).resolve_scale(color='independent')\n",
    "        #chart = alt.layer(chart_effect, area).resolve_scale(color='independent')\n",
    "        charts.append(chart)\n",
    "\n",
    "    combined_chart = alt.vconcat(*charts).resolve_scale(y='independent',  color='independent')\n",
    "    return combined_chart\n",
    "\n",
    "entry_nipah = plot_functional_effect_polymorphism(df_mutations)\n",
    "entry_nipah.display()\n",
    "entry_nipah.save(entry_scores_niv_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65e396-e9bb-46d7-bb8e-d809c10a928e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Make plot of binding by each NiV polymorphism (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49229f69-9373-436e-9f96-bfa8f907767b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_functional_effect_polymorphism_E2(df):\n",
    "    df_mutations = df.rename(columns={'binding_median_E2':'EFNB2','binding_median_E3':'EFNB3'})\n",
    "    df_melted = df_mutations.melt(id_vars=['site','wildtype','mutant'], value_vars=['EFNB2','EFNB3'], \n",
    "                                  var_name='effect', value_name='value')\n",
    "    charts = []\n",
    "    \n",
    "    for effect in ['EFNB2','EFNB3']: \n",
    "        base = alt.Chart(df_melted,title=f'{effect}').encode(\n",
    "            x=alt.X('site:N', title='Site', axis=alt.Axis(labelAngle=-90),\n",
    "                    scale=alt.Scale(domain=list(polymorphisms))),\n",
    "            y=alt.Y('value:Q', title='Binding score'),\n",
    "            tooltip=['effect', 'value', 'site', 'mutant', 'wildtype']\n",
    "        ).transform_filter(\n",
    "            alt.datum.effect == effect\n",
    "        ).properties(\n",
    "            width=500,\n",
    "            height=100\n",
    "        )\n",
    "\n",
    "        chart_effect = base.mark_circle(size=100,opacity=1,color='black').encode(\n",
    "            #color=alt.Color('effect:N', scale=alt.Scale(domain=['EFNB2', 'EFNB3'], range=['#1f4e79', '#ff7f0e']),legend=None)\n",
    "        )\n",
    "        \n",
    "        if effect == 'EFNB2':\n",
    "            rule95 = alt.Chart(pd.DataFrame({'y': [upper_limit_E2_binding]})).mark_rule(color='#1f4e79', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule50 = alt.Chart(pd.DataFrame({'y': [median_E2_binding]})).mark_rule(color='#1f4e79', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule5 = alt.Chart(pd.DataFrame({'y': [lower_limit_E2_binding]})).mark_rule(color='#1f4e79', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "        else:  # effect is EFNB3\n",
    "            rule95 = alt.Chart(pd.DataFrame({'y': [upper_limit_E3_binding]})).mark_rule(color='#ff7f0e', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule50 = alt.Chart(pd.DataFrame({'y': [median_E3_binding]})).mark_rule(color='#ff7f0e', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "            rule5 = alt.Chart(pd.DataFrame({'y': [lower_limit_E3_binding]})).mark_rule(color='#ff7f0e', size=1.5,opacity=0.5).encode(y='y:Q')\n",
    "\n",
    "        chart = alt.layer(chart_effect).resolve_scale(color='independent')\n",
    "        charts.append(chart)\n",
    "\n",
    "    combined_chart = alt.vconcat(*charts).resolve_scale(y='independent', x='independent', color='independent')\n",
    "    return combined_chart\n",
    "\n",
    "niv_poly = plot_functional_effect_polymorphism_E2(df_mutations)\n",
    "niv_poly.display()\n",
    "niv_poly.save(binding_scores_niv_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b773612-5287-4cc8-bc7a-b81a730a55b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot entropy vs mean effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b4f49-06e3-42bd-ba44-4fac8b1e3d8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy_scatter_chart(df,metric,effect):\n",
    "    if effect == 'effect_E2':\n",
    "        effect_name = 'EFNB2'\n",
    "    else:\n",
    "        effect_name = 'EFNB3'\n",
    "    \n",
    "    aggregation = getattr(df.groupby('site')[['effect_E2', 'effect_E3', 'binding_median_E2', 'binding_median_E3']], metric)\n",
    "    means = aggregation().reset_index()\n",
    "    df_total_unique = df.drop_duplicates(subset='site')\n",
    "    df_mean = pd.merge(means, df_total_unique[['entropy','site','henipavirus_entropy']], on='site', how='left')\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_mean['henipavirus_entropy'], df_mean[effect])\n",
    "\n",
    "    print(f'The r value is: {r_value:.2f}')\n",
    "    print(f'The p_value is: {p_value:.2f}')\n",
    "    scatter_chart = alt.Chart(df_mean).mark_point(color='black',size=70, filled=True,opacity=0.5).encode(\n",
    "        x=alt.X('henipavirus_entropy', title=(f\"Henipavirus Entropy\"), axis=alt.Axis(grid=True, tickCount=3),scale=alt.Scale(domain=[-0.2,2.5])),\n",
    "        y=alt.Y(effect, title=(f\"Summed Cell Entry for {effect_name}\"), axis=alt.Axis(grid=True, tickCount=3)),\n",
    "        tooltip=['site'],\n",
    "    ).properties(\n",
    "        width=alt.Step(10),\n",
    "        height=alt.Step(10)\n",
    "    )\n",
    "    # Regression line\n",
    "    reg_df = pd.DataFrame({\n",
    "        'henipavirus_entropy': df_mean['henipavirus_entropy'],\n",
    "        'predicted': intercept + slope * df_mean['henipavirus_entropy']\n",
    "    })\n",
    "\n",
    "    line_chart = alt.Chart(reg_df).mark_line(color='red',opacity=0.5).encode(\n",
    "        x='henipavirus_entropy',\n",
    "        y='predicted'\n",
    "    )\n",
    "\n",
    "    # Combine scatter plot with regression line\n",
    "    combined_chart = scatter_chart + line_chart\n",
    "\n",
    "    return combined_chart\n",
    "\n",
    "    #return chart.display()\n",
    "\n",
    "e2_entry_vs_entropy = entropy_scatter_chart(df_total,'sum','effect_E2')\n",
    "e2_entry_vs_entropy.display()\n",
    "e3_entry_vs_entropy = entropy_scatter_chart(df_total,'sum','effect_E3')\n",
    "e3_entry_vs_entropy.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a85302-2472-4c6d-bd99-492d0d9d1f73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot Functional Effects of Differences with Hendra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b42d98-c540-42b2-9c36-07df260fa523",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_hendra_mutations_E2(df):\n",
    "    df_hendra_comparison = df.rename(columns={'hendra':'mutant'})\n",
    "    df_hendra = pd.merge(df_hendra_comparison,df_merged,on=['site','mutant'],how='inner')\n",
    "    # Melt the dataframe to make it long-form for Altair plotting\n",
    "    df_melted = df_hendra.melt(id_vars=['site','wildtype','hendra'], value_vars=['binding_median_E2','binding_median_E3'], \n",
    "                                  var_name='effect', value_name='value')\n",
    "    \n",
    "    # Altair line plot\n",
    "    chart = alt.Chart(df_melted.query(\"effect == 'binding_median_E2'\")).mark_point(color='black',filled=True,size=70).encode(\n",
    "        x=alt.X('site:N',title='Site',axis=alt.Axis(labelAngle=-90)),\n",
    "        y=alt.Y('value:Q',title='Receptor Binding',axis=alt.Axis(grid=True, tickCount=4)),\n",
    "        tooltip=['site','wildtype','hendra','value'],\n",
    "    ).properties()\n",
    "\n",
    "    chart_master = chart \n",
    "    return chart_master.display()\n",
    "\n",
    "def plot_hendra_mutations_E3(df):\n",
    "    df_hendra_comparison = df.rename(columns={'hendra':'mutant'})\n",
    "    df_hendra = pd.merge(df_hendra_comparison,df_merged,on=['site','mutant'],how='inner')\n",
    "\n",
    "    # Melt the dataframe to make it long-form for Altair plotting\n",
    "    df_melted = df_hendra.melt(id_vars=['site','wildtype','hendra'], value_vars=['binding_median_E2','binding_median_E3'], \n",
    "                                  var_name='effect', value_name='value')\n",
    "    \n",
    "    # Altair line plot\n",
    "    chart = alt.Chart(df_melted.query(\"effect == 'binding_median_E3'\")).mark_point(color='black',filled=True,size=70).encode(\n",
    "        x=alt.X('site:N',title='Site',axis=alt.Axis(labelAngle=-45)),\n",
    "        y=alt.Y('value:Q',title='Receptor Binding'),\n",
    "        tooltip=['site','wildtype','hendra','value'],\n",
    "    ).properties()\n",
    "    \n",
    "    chart_master = chart \n",
    "    return chart_master.display()\n",
    "\n",
    "plot_hendra_mutations_E2(df)\n",
    "plot_hendra_mutations_E3(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738ff5d-b18d-42ca-926a-a06885444399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hendra_mutants(df,virus):\n",
    "    df_hendra_comparison = df.rename(columns={virus:'mutant'})\n",
    "    df_hendra_comparison = df_hendra_comparison[['mutant','site']]\n",
    "    df_hendra = pd.merge(df_hendra_comparison,df_merged,on=['site','mutant'],how='inner')\n",
    "    hendra_sites = list(df_hendra['site'].unique())\n",
    "    print(hendra_sites)\n",
    "    print(len(hendra_sites))\n",
    "    #display(df_hendra)\n",
    "\n",
    "find_hendra_mutants(df,'hendra')\n",
    "find_hendra_mutants(df,'cedar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765a35c-98c9-4dcf-a34b-1ee0101935d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
